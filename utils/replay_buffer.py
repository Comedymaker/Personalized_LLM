# utils/replay_buffer.py
import torch
from models.tokenizer import Tokenizer
import random
class ReplayBuffer:
    def __init__(self, max_size=1000):
        self.max_size = max_size
        self.buffer = []  # [(score, sample_dict)]
        self.seen = set()  # å­˜å‚¨å·²ç»åŠ å…¥çš„ input_ids å“ˆå¸Œå€¼ç”¨äºå»é‡
        self.tokenizer = Tokenizer.load_tokenizer()  # åŠ è½½ tokenizer

    def _hash(self, sample):
        input_ids = sample["input_ids"]
        # å»æ‰å·¦ä¾§çš„ paddingï¼ˆä¹Ÿå¯ä»¥æ ¹æ®å…·ä½“ tokenizer è®¾ç½®å·¦/å³ï¼‰
        unpadded = input_ids[input_ids != self.tokenizer.pad_token_id]
        return tuple(unpadded.tolist())

    def add(self, sample, score):
        sample_hash = self._hash(sample)
        if sample_hash in self.seen:
            # print("sample already exists in buffer, skipping addition.")
            return  # å·²å­˜åœ¨ï¼Œè·³è¿‡æ·»åŠ 
        decoded_input = self.tokenizer.decode(sample["input_ids"], skip_special_tokens=False)
        if len(self.buffer) < self.max_size:
            self.buffer.append((score, sample))
            self.seen.add(sample_hash)
            # print(f"âœ… added sample: {decoded_input} with score: {score}")
        else:
            self.buffer.sort(key=lambda x: x[0])  # å‡åºæ’åˆ—
            if score > self.buffer[0][0]:
                # ç§»é™¤æ—§çš„ sample çš„ hash
                old_sample = self.buffer[0][1]
                old_hash = self._hash(old_sample)
                self.seen.discard(old_hash)

                # æ›¿æ¢æ–°æ ·æœ¬
                self.buffer[0] = (score, sample)
                self.seen.add(sample_hash)
                # print(f"ğŸ”„ replaced with sample: {decoded_input} with score: {score}")

    def get_all(self):
        return [s for _, s in self.buffer]

    def save(self, path):
        torch.save(self.buffer, path)

    def load(self, path, ratio):
        assert 0 < ratio <= 1.0, "ratio must be in (0, 1]"
        all_data = torch.load(path)
        # æŒ‰åˆ†æ•°é™åºæ’åº
        sorted_data = sorted(all_data, key=lambda x: x[0], reverse=True)
        # æˆªå–å‰ä¸€å®šæ¯”ä¾‹çš„æ•°æ®
        cutoff = int(len(sorted_data) * ratio)
        self.buffer = sorted_data[:cutoff]
